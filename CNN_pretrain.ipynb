{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learn from https://www.tensorflow.org/tutorials/images/transfer_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.layers as tfl\n",
    "import seaborn as sn\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get English data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Shitford\\Lectures\\22fall\\CS230\\cs230\\dataset.py:49: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_train_norm = (X_train - X_train_miu)/X_train_std\n",
      "f:\\Shitford\\Lectures\\22fall\\CS230\\cs230\\dataset.py:50: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_valid_norm = (X_valid - X_valid_miu)/X_valid_std\n",
      "f:\\Shitford\\Lectures\\22fall\\CS230\\cs230\\dataset.py:51: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_test_norm = (X_test - X_test_miu)/X_test_std\n"
     ]
    }
   ],
   "source": [
    "# get English data\n",
    "# interfacce function to get splited dataset\n",
    "# resize all audio to (19, 1841) matrix\n",
    "# 1841 is the max size of Japanese audio\n",
    "dataset_collection = dataset.getMFCCDatasetRAVDESS(train_size = 0.6, valid_size = 0.2, test_size = 0.2, cut = False, emotion_number = 3, max_wid = 32, max_len = 1841)\n",
    "\n",
    "eng_X_train = dataset_collection['X_train']\n",
    "eng_Y_train = dataset_collection['Y_train']\n",
    "eng_X_valid = dataset_collection['X_valid']\n",
    "eng_Y_valid = dataset_collection['Y_valid']\n",
    "eng_X_test = dataset_collection['X_test']\n",
    "eng_Y_test = dataset_collection['Y_test']\n",
    "\n",
    "eng_X_train_norm = dataset_collection['X_train_norm']\n",
    "eng_X_valid_norm = dataset_collection['X_valid_norm']\n",
    "eng_X_test_norm = dataset_collection['X_test_norm']\n",
    "\n",
    "# convert array to tensor\n",
    "eng_X_train_norm = tf.convert_to_tensor(eng_X_train_norm)\n",
    "eng_X_valid_norm = tf.convert_to_tensor(eng_X_valid_norm)\n",
    "eng_X_test_norm = tf.convert_to_tensor(eng_X_test_norm)\n",
    "eng_Y_train = tf.convert_to_tensor(eng_Y_train)\n",
    "eng_Y_valid = tf.convert_to_tensor(eng_Y_valid)\n",
    "eng_Y_test = tf.convert_to_tensor(eng_Y_test)\n",
    "\n",
    "eng_X_train = tf.convert_to_tensor(eng_X_train)\n",
    "eng_X_valid = tf.convert_to_tensor(eng_X_valid)\n",
    "eng_X_test = tf.convert_to_tensor(eng_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Japanese data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Shitford\\Lectures\\22fall\\CS230\\cs230\\dataset.py:49: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_train_norm = (X_train - X_train_miu)/X_train_std\n",
      "f:\\Shitford\\Lectures\\22fall\\CS230\\cs230\\dataset.py:50: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_valid_norm = (X_valid - X_valid_miu)/X_valid_std\n",
      "f:\\Shitford\\Lectures\\22fall\\CS230\\cs230\\dataset.py:51: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_test_norm = (X_test - X_test_miu)/X_test_std\n"
     ]
    }
   ],
   "source": [
    "# get Japanese data\n",
    "# interfacce function to get splited dataset\n",
    "# resize all audio to (19, 1841) matrix\n",
    "# 1841 is the max size of Japanese audio\n",
    "dataset_collection = dataset.getMFCCDataset(train_size = 0.6, valid_size = 0.2, test_size = 0.2, cut = False, max_wid = 32, max_len = 1841)\n",
    "\n",
    "jap_X_train = dataset_collection['X_train']\n",
    "jap_Y_train = dataset_collection['Y_train']\n",
    "jap_X_valid = dataset_collection['X_valid']\n",
    "jap_Y_valid = dataset_collection['Y_valid']\n",
    "jap_X_test = dataset_collection['X_test']\n",
    "jap_Y_test = dataset_collection['Y_test']\n",
    "\n",
    "jap_X_train_norm = dataset_collection['X_train_norm']\n",
    "jap_X_valid_norm = dataset_collection['X_valid_norm']\n",
    "jap_X_test_norm = dataset_collection['X_test_norm']\n",
    "\n",
    "# convert array to tensor\n",
    "# jap_X_train_norm = tf.convert_to_tensor(jap_X_train_norm)\n",
    "# jap_X_valid_norm = tf.convert_to_tensor(jap_X_valid_norm)\n",
    "# jap_X_test_norm = tf.convert_to_tensor(jap_X_test_norm)\n",
    "# jap_Y_train = tf.convert_to_tensor(jap_Y_train)\n",
    "# jap_Y_valid = tf.convert_to_tensor(jap_Y_valid)\n",
    "# jap_Y_test = tf.convert_to_tensor(jap_Y_test)\n",
    "\n",
    "# jap_X_train = tf.convert_to_tensor(jap_X_train)\n",
    "# jap_X_valid = tf.convert_to_tensor(jap_X_valid)\n",
    "# jap_X_test = tf.convert_to_tensor(jap_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input pic size is same as spec matrix size (19, 1841)\n",
    "input_shape = (jap_X_train_norm.shape[1], jap_X_train_norm.shape[2], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 32, 1841)\n"
     ]
    }
   ],
   "source": [
    "print(jap_X_train_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_batch = []\n",
    "for i in range(len(jap_X_train_norm)):\n",
    "    temp_feature_batch = np.resize(jap_X_train_norm[i], (1, 32, 1841, 3))\n",
    "    feature_batch.append(temp_feature_batch)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4905652b14e4b7eb92899b78ac499a22c488804455b27940a322fd82aaf71031"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
